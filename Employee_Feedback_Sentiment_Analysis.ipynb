{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Employee Performance Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Project Definition\n",
    "\n",
    "The data for this project is based on employee feedback and annual performance reviews. A nine-box rating is used which measures both Performance and Potential.  This project will attempt to include a sentiment score as part of the NLP prediction to determine if the predictability can be improved.\n",
    "\n",
    "Data was obtained from [Kaggle](https://www.kaggle.com/datasets/fiodarryzhykau/employee-review) where the contributor tested a variety of algorithms to find a model that best predicts the rating. The best predictive accuracy was 30%.\n",
    "\n",
    "Other code in this repository (Sentiment_Scoring_Analysis.ipynb) determined Flair is the best package for scoring this employee performance data.  Will the inclusion of a sentiment score improve the predictive accuracy? \n",
    "\n",
    "\n",
    "\n",
    "## Process\n",
    "\n",
    "> Load data\n",
    "\n",
    "> Calculate Sentiment Score\n",
    "\n",
    "> Tokenize text \n",
    "\n",
    "> XGBoost with Grid Search\n",
    "\n",
    ">> Ordinal Classifier on XGBoost \n",
    "\n",
    "\n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the [rubric](https://review.udacity.com/#!/rubrics/2322/view). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_data(target):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Data for this project was obtained via Kaggle (https://www.kaggle.com/datasets/fiodarryzhykau/employee-review)\n",
    "    On Kaggle, the data had been separated into train & test and stored in 2 separate files. \n",
    "    For this project the files will be merged. Train & test data will be generated within the code. \n",
    "        \n",
    "    INPUT - \n",
    "        target - y value to predict.  This could be the Category, Performance or Potential value. \n",
    "        \n",
    "    OUTPUT - \n",
    "        X & y values for model prediction. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    kaggle_data_test = pd.read_csv('./data/employee_review_mturk_dataset_test_v6_kaggle.csv')\n",
    "\n",
    "    kaggle_data_train = pd.read_csv('./data/employee_review_mturk_dataset_v10_kaggle.csv')\n",
    "\n",
    "    kaggle_data = [kaggle_data_test, kaggle_data_train.rename(columns={'adjusted':'updated'})]\n",
    "\n",
    "    df = pd.concat(\n",
    "        kaggle_data,\n",
    "        axis=0,\n",
    "        join=\"outer\",\n",
    "        ignore_index=False,\n",
    "        keys=None,\n",
    "        levels=None,\n",
    "        names=None,\n",
    "\n",
    "        )\n",
    "\n",
    "    #Split the 'nine_box_category' into 3 columsn ->  'performance' ,  'potential' and 'category'\n",
    "\n",
    "    #split performance & potential values and clean to only include the Low, Moderate, High text \n",
    "    df[['performance', 'potential']] = df['nine_box_category'].str.split(',', 1, expand=True)\n",
    "    df['performance'] = df['performance'].str.split('(').str[1].str.split(' ').str[0]\n",
    "    df['potential'] = df['potential'].str.split(')').str[0].str.split(' ').str[1]\n",
    "\n",
    "    #split nine_box_category string and clean 'category'\n",
    "    #text before colon\n",
    "    df['category'] = df['nine_box_category'].str.split(':').str[0]\n",
    "    #text after space\n",
    "    df['category'] = df['category'].str.split(' ').str[1]\n",
    "\n",
    "    #Drop unnecessary columns \n",
    "    df.drop(['nine_box_category'], axis=1, inplace=True)\n",
    "    \n",
    "    #Keep only records with feedback text\n",
    "    df['feedback'].dropna(inplace=True)\n",
    "    \n",
    "    #Remove rows that contain no characters\n",
    "    df = df[df['feedback'].str.contains('[A-Za-z]')]\n",
    "    \n",
    "    \n",
    "    #For testing - to limit size of dataset\n",
    "    #df=df.sample(n = 100)\n",
    "        \n",
    "    X = df[['feedback','updated','reviewed']]\n",
    "    \n",
    "    y = df[target]\n",
    "    \n",
    "    return X, y \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text and Build Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, punkt\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import contractions\n",
    "      \n",
    "def tokenize(text):\n",
    "    \n",
    "    '''\n",
    "    Process data to remove puncuation, normalize text (lower case) & tokenize data.\n",
    "    Stop words are retained. Words like 'not' must be included for sentiment.\n",
    "    Expand contractions before removing non-ASCII characters. \n",
    "    \n",
    "    INPUT - \n",
    "        'text' - employee feedback text response\n",
    "           \n",
    "    OUTPUT - \n",
    "        'clean_tokens' - text has been cleaned and transformed into tokens \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    #Expand contractions before removing special char\n",
    "    contractions.fix(text)\n",
    "    \n",
    "    #Remove non-Ascii characters \n",
    "    tokens = re.sub(r'[^\\x00-\\x7f]',r' ', str(text))\n",
    "    \n",
    "    #split by white space\n",
    "    tokens = re.sub(r\"[^\\w\\s]\", \" \", str(text))\n",
    "    tokens = word_tokenize(tokens)\n",
    "    #print(tokens)\n",
    "    \n",
    "    #Part of speech tagging\n",
    "    tokens = pos_tag(tokens) \n",
    "    #print(tokens)\n",
    "    \n",
    "    #Remove proper nouns\n",
    "    clean_pos_tokens = [x for (x,y) in tokens if y not in ('NNP', 'NNPS')]\n",
    "    \n",
    "    #lemmatize verbs\n",
    "    clean_verb_tokens =  [lemmatizer.lemmatize(word,pos='v') for word in clean_pos_tokens ]\n",
    "    \n",
    "    #lemmatize nouns\n",
    "    clean_tokens =  [lemmatizer.lemmatize(word,pos='n') for word in clean_verb_tokens ]\n",
    "    \n",
    "    #print(clean_tokens)\n",
    "    \n",
    "    return clean_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Transform - Sentiment Scoring with Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-06 14:04:22,776 loading file C:\\Users\\E073462\\.flair\\models\\sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "#!pip install flair\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "import statistics\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "\n",
    "\n",
    "def sentiment_score(text):\n",
    "    \n",
    "    '''\n",
    "    Flair sentiment scoring is applied to each sentence within a text comment. Comments may have one or more sentences. \n",
    "    The median and standard deviation sentiment score of the sentences is returned.  \n",
    "    This will help identify an employee with a HIGH performance but LOW potential. \n",
    "    \n",
    "    INPUT - \n",
    "        Employee feedback text comment. This may be one or more sentences. \n",
    "                \n",
    "    OUTPUT - \n",
    "        \n",
    "        Sentiment score stddev & median \n",
    "        \n",
    "    '''\n",
    "        \n",
    "    #tokenize text into sentences\n",
    "    #print(text)\n",
    "    sent_scores = list()\n",
    "    sent_scores_med = list()\n",
    "    sent_scores_stddev = list()\n",
    "    sent_polarity = list()\n",
    "    \n",
    "    for t in list(text):\n",
    "        #print(t)\n",
    "        feedback = sent_tokenize(t)\n",
    "        #print(feedback)\n",
    "\n",
    "        \n",
    "        value = list()\n",
    "        score = list()\n",
    "\n",
    "\n",
    "        #Flair only provides a value of POSTIVE or NEGATIVE and a condifence interval\n",
    "        #If polarity is NEGATIVE, the confidence score is changed to negative number\n",
    "        #Using the confidence interval, a value of NEUTRAL will also be created\n",
    "        #Confidence between 0.9 & -0.9 is set to NEUTRAL\n",
    "\n",
    "        #The 0.9 threshold is based on testing & visual examination in 'Sentiment_Scoring_Analysis.ipnb'\n",
    "\n",
    "        for feedback_sent in feedback:\n",
    "            #print(feedback)\n",
    "            sent = Sentence(feedback_sent)\n",
    "            classifier.predict(sent)\n",
    "\n",
    "            if sent.labels[0].value == 'NEGATIVE':\n",
    "                sent.labels[0].score = 0 - sent.labels[0].score\n",
    "            else:\n",
    "                sent.labels[0].score = sent.labels[0].score\n",
    "\n",
    "            value.append(sent.labels[0].value)\n",
    "            score.append(sent.labels[0].score)\n",
    "\n",
    "            #print(sent.labels[0].score, sent.labels[0].value)\n",
    "\n",
    "        confidence = score\n",
    "\n",
    "        confidence_median = statistics.median(confidence)\n",
    "        confidence_stddev = statistics.pstdev(confidence)\n",
    "   \n",
    "        if confidence_median < 0.9 and confidence_median > -0.9:\n",
    "            polarity = 'NEUTRAL'\n",
    "        elif confidence_median >= 0.9:\n",
    "            polarity = 'POSITIVE'\n",
    "        elif confidence_median <= -0.9:\n",
    "            polarity = 'NEGATIVE'\n",
    "        else:\n",
    "            polarity = 'NA'\n",
    "     \n",
    "        sent_scores_med.append(confidence_median)\n",
    "        sent_scores_stddev.append(confidence_stddev)\n",
    "        sent_polarity.append(polarity)\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(sent_scores_med,sent_scores_stddev)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OrdinalClassifier - Leverage Ordinal Order for Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method is suggested on Medium.com as an option to better classify orinal values. \n",
    "#https://medium.com/towards-data-science/simple-trick-to-train-an-ordinal-regression-with-any-classifier-6911183d2a3c\n",
    "#Article: Simple Trick to Train an Ordinal Regression with any Classifier by Muhammad Assagaf\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "class OrdinalClassifier():\n",
    "\n",
    "    def __init__(self, clf):\n",
    "        self.clf = clf\n",
    "        self.clfs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.unique_class = np.sort(np.unique(y))\n",
    "        if self.unique_class.shape[0] > 2:\n",
    "            for i in range(self.unique_class.shape[0]-1):\n",
    "                # for each k - 1 ordinal value we fit a binary classification problem\n",
    "                binary_y = (y > self.unique_class[i]).astype(np.uint8)\n",
    "                clf = clone(self.clf)\n",
    "                clf.fit(X, binary_y)\n",
    "                self.clfs[i] = clf\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs}\n",
    "        predicted = []\n",
    "        for i, y in enumerate(self.unique_class):\n",
    "            if i == 0:\n",
    "                # V1 = 1 - Pr(y > V1)\n",
    "                predicted.append(1 - clfs_predict[i][:,1])\n",
    "            elif i in clfs_predict:\n",
    "                # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n",
    "                 predicted.append(clfs_predict[i-1][:,1] - clfs_predict[i][:,1])\n",
    "            else:\n",
    "                # Vk = Pr(y > Vk-1)\n",
    "                predicted.append(clfs_predict[i-1][:,1])\n",
    "        return np.vstack(predicted).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y = self.predict(X)\n",
    "        return mean_squared_error(y, y_pred)\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Labels as Ordinals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code leveraged from StackOverflow to dictate the order of the label encoding.\n",
    "#https://stackoverflow.com/questions/51308994/python-sklearn-determine-the-encoding-order-of-labelencoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "class MyLabelEncoder(LabelEncoder):\n",
    "\n",
    "    def fit(self, y):\n",
    "        '''\n",
    "        By default LabelEncoder will label based on the order seen within the data.\n",
    "        Low, Moderate, High as well as the 1-9 categories must have order preserved for OrdinalClassifier() \n",
    "        to function as expected        \n",
    "        \n",
    "        '''\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        self.classes_ = pd.Series(y).unique()\n",
    "        return self\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder \n",
    "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "The preprocessing pipline will one-hot encode the Updated & Reviewed features.\n",
    "The feedback comments will leverage FeatureUnion for sentiment score and vectorization\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "ohe_features = ['updated','reviewed']\n",
    "nlp_features = 'feedback'\n",
    "\n",
    "\n",
    "#Calculate a sentiment score for each feedback comment\n",
    "text_transformer = Pipeline([    \n",
    "    ('sentiment_score', FunctionTransformer(sentiment_score, validate=False))\n",
    "])\n",
    "\n",
    "\n",
    "text_union = FeatureUnion([\n",
    "    ('sentiment', text_transformer),\n",
    "    ('tfidf',TfidfVectorizer(tokenizer=tokenize ))\n",
    "])\n",
    "\n",
    "\n",
    "#Prepare data for modeling by encoding, transforming text to a score and tokenizing text.\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('ohe',OneHotEncoder(),ohe_features),\n",
    "        ('text',text_union, nlp_features)\n",
    "        \n",
    "] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_pipeline():\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This pipeline will initiate the preprocessing to encode and transform data before running the model.\n",
    "    A grid search is used to identify the best hyperparemeters for the model.\n",
    "    \n",
    "    NOTE: Ultimately OrdinalClassifier was found to lower the predictive accuracy of the model and is not used. \n",
    "    Model is run without the OrdinalClassifier below.  Line can be uncommented to continue testing with Ordinal \n",
    "    Classifier if desired. \n",
    "        \n",
    "    '''\n",
    "       \n",
    "    \n",
    "\n",
    "    pipeline = Pipeline([\n",
    "            #preprocessing one-hot encodes data; calculates the sentiment score & pre-processes text\n",
    "            ('preprocessor', preprocessor),\n",
    "        \n",
    "            #model predict using XGBClassifier\n",
    "            ('clf', XGBClassifier(use_label_encoder=False, verbosity = 0))\n",
    "            #('clf', OrdinalClassifier(XGBClassifier(use_label_encoder=False, verbosity = 0)))\n",
    "\n",
    "    ])\n",
    "    \n",
    "\n",
    "    parameters = {\n",
    "        \n",
    "        #XGBoost parameters\n",
    "        'clf__learning_rate' : [0.01, 0.05 ,0.1] ,\n",
    "        #'clf__max_depth' : [2, 5, 7 ] ,  #too large means overfit!!\n",
    "        'clf__eval_metric' : ['auc'],\n",
    "        'clf__n_estimators' : [150, 200, 250] #number of 'trees'\n",
    "                          \n",
    "    }\n",
    "\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters) #, n_jobs=-1)\n",
    "\n",
    "    return cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt    \n",
    "\n",
    "def display_results(y_test, y_pred):\n",
    "        \n",
    "    '''\n",
    "    Display results of the model.\n",
    "    Generate a confusion matrix and the f1 score & accuracy.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    labels = np.unique(y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True,cmap=\"OrRd\");\n",
    "    \n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix');     \n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function: Predict Category, Performance & Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def main(target):\n",
    "    \n",
    "    #Load data and assign X, y values \n",
    "    X, y = load_data(target)\n",
    "    \n",
    "    #Encode target variable. For OrdinalClassifier() labels must be ordered correctly (low, Moderate, High, etc.)\n",
    "    #By default LabelEncoder orders by order of appearance in data\n",
    "    label_encoder = MyLabelEncoder()\n",
    "    \n",
    "    if target == 'category':\n",
    "        label_encoder = label_encoder.fit(['1','2','3','4','5','6','7','8','9']) \n",
    "    else:\n",
    "        label_encoder = label_encoder.fit(['Low','Moderate','High' ])\n",
    "\n",
    "    #Encode y values\n",
    "\n",
    "    label_encoded_y = label_encoder.transform(y) \n",
    "    \n",
    "    #print(y, label_encoded_y )    \n",
    "    \n",
    "    #Split train/test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,label_encoded_y, test_size=0.3, random_state=42 ) \n",
    "    \n",
    "    #classes = len(pd.unique(label_encoded_y)) \n",
    "    \n",
    "    #print(y_train)\n",
    "    \n",
    "    #Excute the model pipeline\n",
    "    model = model_pipeline()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    \n",
    "    display_results(y_test, y_pred)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict based on Category: 1-9\n",
    "main('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict based on Performance: Low, Moderate, High\n",
    "#main('performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict based on Potential: Low, Moderate, High\n",
    "#main('potential')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
